# Projet_introDL

# BiLSTM-CRF for Named Entity Recognition (NER)

Ce projet vise Ã  reproduire les rÃ©sultats de lâ€™article **"Bidirectional LSTM-CRF Models for Sequence Tagging"** (Huang et al., 2015), en appliquant une architecture BiLSTM-CRF Ã  la tÃ¢che de reconnaissance dâ€™entitÃ©s nommÃ©es (NER) sur le dataset **CoNLL-2003**.

## ğŸ¯ Objectif

- ImplÃ©menter un modÃ¨le BiLSTM-CRF en PyTorch.
- EntraÃ®ner ce modÃ¨le sur les donnÃ©es CoNLL-2003.
- Suivre les performances via TensorBoard.
- Appliquer des techniques modernes comme lâ€™early stopping, le learning rate scheduler, la rÃ©gularisation (dropout, weight decay).
- Observer le comportement du modÃ¨le : overfitting, stabilitÃ© des gradients, etc.

## ğŸ“¦ Structure du projet

â”œâ”€â”€ main.ipynb # Notebook principal avec tout le pipeline (prÃ©traitement, modÃ¨le, entraÃ®nement) â”œâ”€â”€ model.py # DÃ©finition du modÃ¨le BiLSTM-CRF (optionnel si sÃ©parÃ©) â”œâ”€â”€ requirements.txt # Librairies nÃ©cessaires â”œâ”€â”€ runs/ # Logs TensorBoard â”œâ”€â”€ README.md # Ce fichier


## ğŸ“š Dataset

Le dataset **CoNLL-2003** est automatiquement tÃ©lÃ©chargÃ© via la librairie ğŸ¤— `datasets`.

```python
from datasets import load_dataset
dataset = load_dataset("conll2003")
âš™ï¸ PrÃ©requis

Ce projet est conÃ§u pour Ãªtre exÃ©cutÃ© sur Google Colab avec GPU activÃ©.

Installation des dÃ©pendances (Colab)
!pip install datasets transformers torch torchvision torchaudio torchcrf tensorboard
ğŸ—ï¸ EntraÃ®nement du modÃ¨le

L'entraÃ®nement se fait via une fonction train_model() qui :

applique un early stopping,
ajuste dynamiquement le learning rate avec un scheduler,
enregistre les courbes dans TensorBoard,
log les gradients et poids pour surveiller les problÃ¨mes de vanishing/exploding gradients.
Lancer l'entraÃ®nement :
train_model(model, train_dataloader, val_dataloader, epochs=20, learning_rate=0.0005)
ğŸ“Š Visualisation avec TensorBoard

Dans Colab :

%load_ext tensorboard
%tensorboard --logdir=runs/
Vous y verrez :

Loss/Train
Loss/Validation
Accuracy
Learning Rate
Histograms des poids et gradients
ğŸ” RÃ©sultats obtenus

ParamÃ¨tres	Score
hidden_dim = 256	
dropout = 0.5	
learning rate = 0.001	
loss initiale	2.19
perte finale (val)	~1.6
MalgrÃ© des performances encourageantes, le modÃ¨le nâ€™atteint pas les scores exacts de lâ€™article original, probablement Ã  cause de diffÃ©rences dans le tokenizer, lâ€™optimisation, et le fine-tuning non rÃ©alisÃ© sur BERT.
âœï¸ Auteur

Projet rÃ©alisÃ© dans le cadre d'un travail acadÃ©mique en Deep Learning.
